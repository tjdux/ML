{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP35xNYWYaHiLQZF4Ga7Z+j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjdux/basic_of_ml/blob/main/21_sequential_data_and_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 순차 데이터 (sequential data)\n",
        "- **순차 데이터**\n",
        "  - 순서에 의미가 있는 데이터\n",
        "  - e.g. 텍스트, 시계열 데이터\n",
        "- 순서에 유지하며 신경망에 주입\n",
        "- 이전에 입력한 데이터를 기억하는 기능 필요\n",
        "- FFNN, RNN\n",
        "  - **피드포워드 신경망** (feedforward neural network; FFNN)\n",
        "    - 입력 데이터의 흐름이 앞으로만 전달되는 신경망\n",
        "    - e.g. 완전 연결 신경망, 합성곱 신경망\n",
        "  - 순환 신경망: 다음 샘플을 위해서 이전 데이터가 신경망 층에 순환되는 신경망"
      ],
      "metadata": {
        "id": "dYMax1xDZKA3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 순환 신경망 (recurrent neural network; RNN)\n",
        "- 완전 연결 신경망에 이전 데이터의 처리 흐름을 순환하는 고리 하나만 추가\n",
        "- 뉴런의 출력이 다시 자기 자신으로 전달: 어떤 샘플을 처리할 때 바로 이전에 사용했던 데이터를 재사용\n",
        "  - A, B, C 3개의 샘플을 처리하는 RNN을 가정\n",
        "  - 1️⃣ A를 처리하고 난 출력 ($O_A$)가 다시 뉴런으로 들어감\n",
        "  - 2️⃣ B를 처리할 때 $O_A$를 함께 사용하여 $O_B$ 출력 👉 $O_B$에는 A에 대한 정보가 어느 정도 포함\n",
        "  - 3️⃣ C를 처리할 때 $O_B$를 함께 사용하여 $O_C$를 출력 👉 $O_C$에는 A에 대한 정보보다는 B에 대한 정보가 더 많이 포함\n",
        "- **타임스텝**(timestep): 샘플을 처리하는 한 단계\n",
        "  - 이전 타임스텝의 샘플을 기억하지만 타임스텝이 오래될수록 순환되는 정보는 희미해짐\n",
        "- **셀**(cell): RNN에서 층을 부르는 이름\n",
        "  - 한 셀에는 여러 뉴런이 있지만 RNN에서는 뉴런을 모두 표시하지 않고 하나의 셀로 층을 표현\n",
        "  - **은닉 상태**(hidden state): 셀의 출력\n",
        "![img](https://velog.velcdn.com/images/qorgns1115/post/639033bd-f68d-4fcf-a871-da499d59f7c1/image.png)\n",
        "- 일반적으로 은닉층의 활성화 함수로는 tanh을 많이 사용\n",
        "  - -1~1의 범위\n",
        "\n",
        "  ![img](https://i.namu.wiki/i/vuYcHXTr0JgsZ7jB8Jxk1UpUYkiIcvZs9L3uVNiLxpYnwb_iNUQXQNj8sxUh92pjLzC1Bz0cEENfQ186QWkEmQ.webp)\n",
        "  - 그림에는 활성화함수를 표시하지 않지만, RNN에서도 활성화 함수가 필요!\n",
        "- RNN에는 이전 타임스텝의 은닉 상태에 곱해지는 가중치가 존재\n",
        "  - $w_X$: 입력에 곱해지는 가중치\n",
        "  - $w_h$: 이전 타임스텝의 은닉 상태에 곱해지는 가중치\n",
        "  - 뉴런마다 하나의 절편이 포함되지만 표시는 안 함\n",
        "\n",
        "  ![img](https://velog.velcdn.com/images/jaekyu_lim/post/e1c3b1cf-81f9-4319-9d35-d286ca7f981f/image.png)\n",
        "- '타임스텝으로 펼침': RNN을 타임스텝마다 그리기\n",
        "  ![img](https://velog.velcdn.com/images/dltpdl31/post/9f553d54-926d-4c4a-b189-c29a4684df93/image.png)\n",
        "  - 모든 타임스텝에서 사용되는 가중치 $w_h$는 하나\n",
        "  - $w_h$: 타임스텝에 따라 변화되는 뉴런의 출력을 학습\n",
        "  - $h_0$은 모두 0으로 초기화\n"
      ],
      "metadata": {
        "id": "Z6AEwQjkZwmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 셀의 가중치와 입출력"
      ],
      "metadata": {
        "id": "ZYg9YirxdIzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 셀에서 필요한 가중치의 크기\n",
        "![img](https://velog.velcdn.com/images/jaekyu_lim/post/9aeb05b4-d806-46ec-9271-9237ad8f7afa/image.png)\n",
        "- $w_X$의 크기: 4 * 3 = 12\n",
        "\n",
        "![img](https://velog.velcdn.com/images/jaekyu_lim/post/c1071c67-f987-4e53-8fb3-2bf967faf291/image.png)\n",
        "- 첫 번째 뉴런 ($r_1$)의 은닉 상태가 다음 타임스텝에 재사용될 때 첫 번째 뉴런과 두 번째 뉴런, 세 번째 뉴런에 모두 전달됨\n",
        "- 이전 타임스텝의 은닉 상태는 다음 타임스텝의 모든 뉴런에 완전히 연결됨\n",
        "- 은닉 상태가 모든 뉴런에 순환되기 때문에 완전 연결 신경망처럼 그림으로 표현하기 어려움  \n",
        "- 👉 $w_h$의 크기: 3 * 3 = 9\n"
      ],
      "metadata": {
        "id": "NRzNrXz9dKtl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 모델 파라미터 개수\n",
        "- 각 뉴런마다 하나의 절편\n",
        "\n",
        "$$모델 파라미터 수 = w_X + w_h + 절편 = 12 + 9 + 3 = 24$$"
      ],
      "metadata": {
        "id": "bKRXV4eNd40L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 순환층의 입력과 출력\n",
        "- 순환층은 일반적으로 샘플마다 2개의 차원을 가짐\n",
        "  - 하나의 샘플을 하나의 시퀀스(sequence)라고 말함\n",
        "  - 시퀀스 안에는 여러 개의 아이템\n",
        "  - 시퀀스의 길이 == 타임스텝의 길이\n",
        "  - 'I am a boy\"의 타임스텝 크기: `(1, 4, 3)`\n",
        "- 입력이 순환층을 통과하면 두 번째, 세 번째 차원이 사라지고 순환층의 뉴런 개수만큼 출력\n",
        "![img](https://velog.velcdn.com/images%2Fcha-suyeon%2Fpost%2F3b96362c-32ad-438e-9061-8a2c378ab6ec%2Fimage.png)\n",
        "  - 하나의 샘플: 시퀀스 길이 (단어 개수)와 단어 표현의 2차원 배열\n",
        "  - ➡️ 순환층을 통과하면 1차원 배열로 바뀌며, 이 크기는 순환층의 뉴런 개수에 의해 결정됨\n",
        "  - 순환층은 기본적으로 마지막 타임스텝의 은닉 상태만 출력으로 내보냄\n",
        "    ![img](https://velog.velcdn.com/images/jeonghyunje/post/956b4a86-0aae-4e5c-b562-11150686c963/image.png)\n",
        "  - 👉 마치 입력된 시퀀스 길이를 모두 읽어서 정보를 마지막 은닉 상태에 압축하여 전달하는 것처럼 볼 수 있음\n"
      ],
      "metadata": {
        "id": "m6dfo0TPeLb2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 여러 개의 순환층이 있을 때 셀의 출력\n",
        "- 셀의 입력: 샘플마다 타임스텝과 단어 표현으로 이루어진 2차원 배열\n",
        "- 👉 마지막 셀을 제외한 다른 모든 셀은 모든 타임스텝의 은닉 상태를 출력\n",
        "![img](https://velog.velcdn.com/images/jeonghyunje/post/2bf6a64f-21ce-49ad-9f66-ea985f3e25e5/image.png)"
      ],
      "metadata": {
        "id": "oCE3BY7ggQbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 출력층의 구성\n",
        "- 다중 분류: 출력층에 클래스 개수만큼 뉴런을 두고 소프트맥스 활성화 함수 사용\n",
        "- 이진 분류: 하나의 뉴런을 두고 시그모이드 활성화 함수 사용\n",
        "- 마지막 셀의 차원이 1차원 👉 `Flatten` 클래스로 펼칠 필요 없음 (셀의 출력을 그대로 밀집층에 사용 가능)\n",
        "![img](https://velog.velcdn.com/images%2Fcha-suyeon%2Fpost%2F5e0209ff-efba-4e29-9dfb-481dab64cb73%2Fimage.png)"
      ],
      "metadata": {
        "id": "YgoS47DMg2uB"
      }
    }
  ]
}